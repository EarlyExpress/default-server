spring:
  application:
    name: ${APP_NAME:default-server}

  profiles:
    active: ${APP_PROFILE:local}

  # Config Server 설정 - Eureka를 통한 자동 탐색
  config:
    import: 'optional:configserver:'

  # Spring Cloud 통합 설정
  cloud:
    # Config Server Discovery 설정
    config:
      discovery:
        enabled: true
        service-id: config-server
      allow-override: true
      override-none: true
      override-system-properties: false
      fail-fast: false # 개발 환경에서 Config Server 없이도 실행 가능
      retry:
        initial-interval: 1000
        max-attempts: 3
        max-interval: 2000
        multiplier: 1.1

    # Kafka Stream 설정
    stream:
      kafka:
        binder:
          brokers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092,localhost:9093,localhost:9094}
          auto-create-topics: true
          replication-factor: 3
          min-partition-count: 3
      bindings:
        # 예제 바인딩 - 실제 사용시 수정
        input:
          destination: ${spring.application.name}-input
          group: ${spring.application.name}-group
          consumer:
            concurrency: 3
        output:
          destination: ${spring.application.name}-output
          producer:
            partition-count: 3

  # Database 설정
  datasource:
    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:default_db}
    username: ${DB_USERNAME:postgres}
    password: ${DB_PASSWORD:postgres}
    driver-class-name: org.postgresql.Driver
    hikari:
      connection-timeout: 30000
      maximum-pool-size: 10
      minimum-idle: 5
      idle-timeout: 600000
      max-lifetime: 1800000

  # JPA 설정
  jpa:
    hibernate:
      ddl-auto: create-drop  # 개발 환경용 - 운영에서는 validate로 변경 필요
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
        default_schema: app
        jdbc:
          batch_size: 20
        order_inserts: true
        order_updates: true
    show-sql: false

  # Kafka 설정
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092,localhost:9093,localhost:9094}

    # Producer 설정
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      acks: all
      retries: 3
      properties:
        enable.idempotence: true
        max.in.flight.requests.per.connection: 5

    # Consumer 설정
    consumer:
      group-id: ${KAFKA_CONSUMER_GROUP_ID:${spring.application.name}-group}
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      auto-offset-reset: earliest
      enable-auto-commit: false
      properties:
        spring.json.trusted.packages: "*"
        isolation.level: read_committed

    # Listener 설정
    listener:
      ack-mode: manual
      concurrency: 3

# Server 포트 설정
server:
  port: ${APP_PORT:4000}
  shutdown: graceful

# Eureka 설정
eureka:
  instance:
    prefer-ip-address: false  # hostname 사용
    hostname: ${EUREKA_INSTANCE_HOSTNAME:${spring.application.name}}
    instance-id: ${eureka.instance.hostname}:${server.port}
    lease-renewal-interval-in-seconds: 10
    lease-expiration-duration-in-seconds: 30
    metadata-map:
      zone: ${ENVIRONMENT:local}
      version: ${version:0.0.1-SNAPSHOT}
  client:
    register-with-eureka: true
    fetch-registry: true
    service-url:
      defaultZone: ${EUREKA_DEFAULT_ZONE:http://localhost:3150/eureka/,http://localhost:3151/eureka/}
    registry-fetch-interval-seconds: 5

# Actuator 설정
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus,env,configprops
  endpoint:
    health:
      show-details: always
  tracing:
    sampling:
      probability: 1.0
  zipkin:
    tracing:
      endpoint: ${ZIPKIN_BASE_URL:http://localhost:9411}/api/v2/spans
  metrics:
    export:
      prometheus:
        enabled: true

# Logging 설정
logging:
  level:
    com.earlyexpress: DEBUG
    org.springframework.cloud: INFO
    org.springframework.kafka: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/${spring.application.name}.log
    max-size: 10MB
    max-history: 30

# WebClient 설정
webclient:
  timeout:
    connection: ${WEBCLIENT_CONNECTION_TIMEOUT:5000}
    read: ${WEBCLIENT_READ_TIMEOUT:10000}
    write: ${WEBCLIENT_WRITE_TIMEOUT:10000}
  max-memory-size: ${WEBCLIENT_MAX_MEMORY_SIZE:10485760}  # 10MB
  connection-provider:
    max-connections: ${WEBCLIENT_MAX_CONNECTIONS:500}
    max-idle-time: 20s
    max-life-time: 60s
    pending-acquire-timeout: 60s
    evict-in-background: 120s